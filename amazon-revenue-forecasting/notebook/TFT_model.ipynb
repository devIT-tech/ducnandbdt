{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8328819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thông tin ban đầu về dữ liệu:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       1000 non-null   int64  \n",
      " 1   parent_asin      1000 non-null   object \n",
      " 2   rating           1000 non-null   float64\n",
      " 3   text             1000 non-null   object \n",
      " 4   user_id          1000 non-null   object \n",
      " 5   date             1000 non-null   object \n",
      " 6   title            1000 non-null   object \n",
      " 7   price            449 non-null    float64\n",
      " 8   average_rating   1000 non-null   float64\n",
      " 9   rating_number    1000 non-null   int64  \n",
      " 10  categories       1000 non-null   object \n",
      " 11  features         1000 non-null   object \n",
      " 12  description      1000 non-null   object \n",
      " 13  main_category    957 non-null    object \n",
      " 14  store            997 non-null    object \n",
      " 15  sentiment_score  1000 non-null   int64  \n",
      "dtypes: float64(3), int64(3), object(10)\n",
      "memory usage: 125.1+ KB\n",
      "None\n",
      "\n",
      "5 dòng đầu tiên:\n",
      "   Unnamed: 0 parent_asin  rating  \\\n",
      "0           0  B00024WC7S     5.0   \n",
      "1           1  B0007GHCT4     5.0   \n",
      "2           2  B000AS2IHA     1.0   \n",
      "3           3  B000B55AFE     5.0   \n",
      "4           4  B000B55AFE     3.0   \n",
      "\n",
      "                                                text  \\\n",
      "0  The strap looks nice and feels good to the tou...   \n",
      "1  Perfectly satisfied with this watch.  Attracti...   \n",
      "2  TERRIBLE slipper and wholly misleading!<br />U...   \n",
      "3  It had been a long time since I wore a watch s...   \n",
      "4                        This is a very small watch.   \n",
      "\n",
      "                        user_id        date  \\\n",
      "0  AFP44HHAU6AL4OOITWSSKWXAQWSA  2015-07-24   \n",
      "1  AFLLYUDRBJPI57I3DW5FGXISWEUA  2014-10-24   \n",
      "2  AFJBCIDY52BFKDVIFSXHHFBQV4CA  2016-04-01   \n",
      "3  AEJ3HIYTHOK7RAUBYO3BKDF7WHZA  2012-10-06   \n",
      "4  AGG5MBN2YSRNRREQPNTF7JKFYCLQ  2017-06-09   \n",
      "\n",
      "                                               title  price  average_rating  \\\n",
      "0  Voguestrap, Comfort Strap, Black Genuine Leath...    NaN             4.1   \n",
      "1  Timex Women's T26301 Kendall Circle Two-Tone S...   41.3             4.6   \n",
      "2  Tamarac by Slippers International Women's Fluf...    NaN             4.4   \n",
      "3       Timex T41711Analog Quartz Camper Green Watch    NaN             3.9   \n",
      "4       Timex T41711Analog Quartz Camper Green Watch    NaN             3.9   \n",
      "\n",
      "   rating_number                                         categories  \\\n",
      "0            327  ['Clothing, Shoes & Jewelry', 'Men', 'Watches'...   \n",
      "1            970  ['Clothing, Shoes & Jewelry', 'Women', 'Watche...   \n",
      "2            759  ['Clothing, Shoes & Jewelry', 'Deal of the Day...   \n",
      "3            738  ['Clothing, Shoes & Jewelry', 'Women', 'Watche...   \n",
      "4            738  ['Clothing, Shoes & Jewelry', 'Women', 'Watche...   \n",
      "\n",
      "                                            features  \\\n",
      "0  ['Voguestrap Comfort Strap, 18mm Black Genuine...   \n",
      "1  ['Two-tone 9mm stainless steel expansion band ...   \n",
      "2  ['100% Suede', 'Dyed Lamb Fur (Fur Origin: Chi...   \n",
      "3  ['Military-Inspired Black Dial with Full Arabi...   \n",
      "4  ['Military-Inspired Black Dial with Full Arabi...   \n",
      "\n",
      "                                         description   main_category  \\\n",
      "0  [\"TX48318BK Size: 18 mm Features: -Watch band....  AMAZON FASHION   \n",
      "1  ['Our Main Street Collection is designed with ...  AMAZON FASHION   \n",
      "2  [\"The Fluff scuff from Slippers International ...  AMAZON FASHION   \n",
      "3  [\"You can tell a lot about a man by the watch ...  AMAZON FASHION   \n",
      "4  [\"You can tell a lot about a man by the watch ...  AMAZON FASHION   \n",
      "\n",
      "                               store  sentiment_score  \n",
      "0                         Voguestrap               -1  \n",
      "1                              Timex                1  \n",
      "2  Tamarac by Slippers International                1  \n",
      "3                              Timex               -1  \n",
      "4                              Timex               -1  \n",
      "\n",
      "Thống kê mô tả cho các cột số:\n",
      "        Unnamed: 0       rating       price  average_rating  rating_number  \\\n",
      "count  1000.000000  1000.000000  449.000000     1000.000000    1000.000000   \n",
      "mean    499.500000     4.091000   34.785033        4.222000    2110.835000   \n",
      "std     288.819436     1.313943   41.368673        0.455723    3777.228909   \n",
      "min       0.000000     1.000000    3.990000        1.000000       1.000000   \n",
      "25%     249.750000     4.000000   11.790000        4.000000      55.750000   \n",
      "50%     499.500000     5.000000   20.900000        4.300000     497.000000   \n",
      "75%     749.250000     5.000000   39.950000        4.500000    1638.000000   \n",
      "max     999.000000     5.000000  249.950000        5.000000   20334.000000   \n",
      "\n",
      "       sentiment_score  \n",
      "count      1000.000000  \n",
      "mean          0.454000  \n",
      "std           0.891448  \n",
      "min          -1.000000  \n",
      "25%          -1.000000  \n",
      "50%           1.000000  \n",
      "75%           1.000000  \n",
      "max           1.000000  \n",
      "\n",
      "Kiểm tra giá trị thiếu:\n",
      "Unnamed: 0           0\n",
      "parent_asin          0\n",
      "rating               0\n",
      "text                 0\n",
      "user_id              0\n",
      "date                 0\n",
      "title                0\n",
      "price              551\n",
      "average_rating       0\n",
      "rating_number        0\n",
      "categories           0\n",
      "features             0\n",
      "description          0\n",
      "main_category       43\n",
      "store                3\n",
      "sentiment_score      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import ast # Để chuyển đổi chuỗi biểu diễn list/dict thành đối tượng Python\n",
    "\n",
    "df = pd.read_csv('pd.csv')\n",
    "\n",
    "\n",
    "# Xóa cột index không tên nếu có (dựa trên mô tả của bạn)\n",
    "if df.columns[0].strip() == '':\n",
    "    df = df.iloc[:, 1:]\n",
    "\n",
    "print(\"Thông tin ban đầu về dữ liệu:\")\n",
    "print(df.info())\n",
    "print(\"\\n5 dòng đầu tiên:\")\n",
    "print(df.head())\n",
    "print(\"\\nThống kê mô tả cho các cột số:\")\n",
    "print(df.describe())\n",
    "print(\"\\nKiểm tra giá trị thiếu:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "968fb51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kiểm tra giá trị thiếu sau tiền xử lý cơ bản:\n",
      "Unnamed: 0          0\n",
      "parent_asin         0\n",
      "rating              0\n",
      "text                0\n",
      "user_id             0\n",
      "date                0\n",
      "title               0\n",
      "price               0\n",
      "average_rating      0\n",
      "rating_number       0\n",
      "categories          0\n",
      "features            0\n",
      "description         0\n",
      "main_category      43\n",
      "store               3\n",
      "sentiment_score     0\n",
      "categories_list     0\n",
      "features_list       0\n",
      "time_idx            0\n",
      "dtype: int64\n",
      "\n",
      "5 dòng sau khi tạo time_idx:\n",
      "(1000, 19)\n"
     ]
    }
   ],
   "source": [
    "# 1. Chuyển đổi cột 'date' sang kiểu datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 2. Xử lý giá trị thiếu cho 'price'\n",
    "# Ví dụ: điền bằng 0 hoặc giá trị trung bình/median.\n",
    "# Một cách tiếp cận tốt hơn có thể là sử dụng một giá trị đặc biệt hoặc một cờ báo thiếu.\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce') # Đảm bảo là số, lỗi sẽ thành NaN\n",
    "df['price'] = df['price'].fillna(0) # Điền NaN bằng 0 (ví dụ)\n",
    "\n",
    "# 3. Đảm bảo các cột số khác là kiểu số\n",
    "numerical_cols = ['rating', 'average_rating', 'rating_number', 'sentiment_score']\n",
    "for col in numerical_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# 4. Xử lý giá trị thiếu cho các cột quan trọng (ví dụ: loại bỏ dòng nếu 'rating' thiếu)\n",
    "df.dropna(subset=['rating', 'parent_asin', 'date'], inplace=True)\n",
    "\n",
    "# 5. Phân tích cú pháp các cột dạng chuỗi list (categories, features, description)\n",
    "def parse_string_list_safe(s):\n",
    "    if pd.isna(s):\n",
    "        return []\n",
    "    try:\n",
    "        # Chuỗi description có vẻ như là list của một string JSON, rồi lại string\n",
    "        # Cần kiểm tra định dạng cụ thể của cột này\n",
    "        if isinstance(s, str) and s.startswith(\"[['\") and s.endswith(\"']]\"): # Dạng đặc biệt\n",
    "             try:\n",
    "                 # Thử loại bỏ các dấu ngoặc kép và ký tự escape không cần thiết\n",
    "                 # Đây là phỏng đoán dựa trên dữ liệu mẫu, cần kiểm tra kỹ\n",
    "                 s_cleaned = s.replace('\\\\\"', '\"') # Thay thế \\\" bằng \"\n",
    "                 parsed_outer_list = ast.literal_eval(s_cleaned)\n",
    "                 if isinstance(parsed_outer_list, list) and len(parsed_outer_list) > 0:\n",
    "                     # Nếu bên trong là một list các chuỗi JSON, ta có thể cần phân tích thêm\n",
    "                     # Hiện tại, chỉ lấy chuỗi đầu tiên nếu nó là chuỗi\n",
    "                     inner_content = parsed_outer_list[0]\n",
    "                     if isinstance(inner_content, list) and len(inner_content) > 0 and isinstance(inner_content[0], str):\n",
    "                         return [inner_content[0]] # Trả về list chứa chuỗi đó\n",
    "                 return [] # Trả về list rỗng nếu không xử lý được\n",
    "             except:\n",
    "                 return [s] # Nếu vẫn lỗi, trả về chuỗi gốc trong list\n",
    "\n",
    "        # Đối với categories và features\n",
    "        evaluated_list = ast.literal_eval(s)\n",
    "        if isinstance(evaluated_list, list):\n",
    "            return evaluated_list\n",
    "        else:\n",
    "            return [str(evaluated_list)] # Nếu không phải list, biến nó thành list một phần tử\n",
    "    except (ValueError, SyntaxError, TypeError):\n",
    "        return [s] if isinstance(s, str) else [] # Nếu lỗi, trả về chuỗi gốc trong list hoặc list rỗng\n",
    "\n",
    "df['categories_list'] = df['categories'].apply(parse_string_list_safe)\n",
    "df['features_list'] = df['features'].apply(parse_string_list_safe)\n",
    "# Cột description có vẻ phức tạp hơn, cần xem xét kỹ định dạng\n",
    "# df['description_list'] = df['description'].apply(parse_string_list_safe)\n",
    "\n",
    "# 6. Sắp xếp dữ liệu theo group_id (sản phẩm) và thời gian\n",
    "df.sort_values(by=['parent_asin', 'date'], inplace=True)\n",
    "\n",
    "# 7. Tạo 'time_idx': một chỉ số thời gian số nguyên liên tục cho mỗi nhóm\n",
    "df['time_idx'] = df.groupby('parent_asin').cumcount()\n",
    "\n",
    "print(\"\\nKiểm tra giá trị thiếu sau tiền xử lý cơ bản:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n5 dòng sau khi tạo time_idx:\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ad6b0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 dòng sau khi thêm đặc trưng thời gian:\n",
      "        date  time_idx month  year day_of_week         main_cat_from_list\n",
      "0 2015-07-24         0     7  2015           4  Clothing, Shoes & Jewelry\n",
      "1 2014-10-24         0    10  2014           4  Clothing, Shoes & Jewelry\n",
      "2 2016-04-01         0     4  2016           4  Clothing, Shoes & Jewelry\n",
      "3 2012-10-06         0    10  2012           5  Clothing, Shoes & Jewelry\n",
      "4 2017-06-09         1     6  2017           4  Clothing, Shoes & Jewelry\n"
     ]
    }
   ],
   "source": [
    "# 1. Trích xuất các đặc trưng từ 'date' (time-varying known)\n",
    "df['month'] = df['date'].dt.month.astype(str)\n",
    "df['year'] = df['date'].dt.year.astype(str)\n",
    "df['day_of_week'] = df['date'].dt.dayofweek.astype(str)\n",
    "df['day_of_month'] = df['date'].dt.day.astype(str)\n",
    "df['day_of_year'] = df['date'].dt.dayofyear.astype(float) # Dạng số thực\n",
    "df['week_of_year'] = df['date'].dt.isocalendar().week.astype(str)\n",
    "\n",
    "\n",
    "# 2. Xử lý các đặc trưng dạng list (categories_list, features_list)\n",
    "# Ví dụ đơn giản: lấy phần tử đầu tiên làm đại diện hoặc tạo đặc trưng one-hot/multi-hot\n",
    "df['main_cat_from_list'] = df['categories_list'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else 'Unknown')\n",
    "\n",
    "# 3. Các đặc trưng văn bản:\n",
    "# Hiện tại, chúng ta có 'sentiment_score'.\n",
    "# Nếu muốn phức tạp hơn, bạn có thể:\n",
    "# - Sử dụng TF-IDF cho 'text', 'title'.\n",
    "# - Sử dụng word/sentence embeddings (ví dụ: SentenceBERT) cho 'text', 'title', 'features', 'description'.\n",
    "#   Việc này sẽ tạo ra các vector số thực, có thể được thêm vào `time_varying_unknown_reals`.\n",
    "#   Ví dụ (khái niệm):\n",
    "#   from sentence_transformers import SentenceTransformer\n",
    "#   model_st = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "#   df['text_embedding'] = df['text'].apply(lambda x: model_st.encode(str(x)))\n",
    "#   # Sau đó, bạn cần tách embedding thành nhiều cột hoặc xử lý nó dưới dạng một vector.\n",
    "\n",
    "# 4. Chuyển đổi các cột categorical sang kiểu 'category' của Pandas\n",
    "# (PyTorch Forecasting sẽ xử lý chúng, nhưng việc khai báo rõ ràng là tốt)\n",
    "categorical_cols_static = ['parent_asin', 'store', 'main_category', 'main_cat_from_list']\n",
    "categorical_cols_time_varying = ['month', 'year', 'day_of_week', 'day_of_month', 'week_of_year']\n",
    "\n",
    "for col in categorical_cols_static + categorical_cols_time_varying:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).astype('category')\n",
    "\n",
    "print(\"\\n5 dòng sau khi thêm đặc trưng thời gian:\")\n",
    "print(df[['date', 'time_idx', 'month', 'year', 'day_of_week', 'main_cat_from_list']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "820dd98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số dòng sau khi lọc các chuỗi ngắn: 335\n",
      "TimeSeriesDataSet và DataLoaders đã được tạo thành công.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_22144\\2600318772.py:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  series_lengths = df.groupby('parent_asin')['time_idx'].count()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.data import GroupNormalizer, NaNLabelEncoder\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, QuantileLoss\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "\n",
    "import pytorch_forecasting\n",
    "\n",
    "\n",
    "# Xác định các tham số cho TimeSeriesDataSet\n",
    "# max_encoder_length: số lượng bản ghi quá khứ mà mô hình sẽ xem xét.\n",
    "# max_prediction_length: số lượng bản ghi tương lai mà mô hình sẽ dự đoán.\n",
    "# Vì chúng ta dự đoán rating cho mỗi review, có thể prediction_length = 1.\n",
    "# Tuy nhiên, TFT được thiết kế để dự đoán một chuỗi, nên chúng ta có thể giữ nó > 1\n",
    "# và chỉ quan tâm đến dự đoán đầu tiên, hoặc dự đoán rating trung bình trong khoảng đó.\n",
    "# Hãy bắt đầu với việc dự đoán rating tại bước thời gian tiếp theo.\n",
    "max_encoder_length = 2  # Ví dụ: xem xét 30 đánh giá trước đó của sản phẩm\n",
    "max_prediction_length = 1 # Dự đoán rating cho đánh giá tiếp theo\n",
    "\n",
    "# Lọc bỏ các chuỗi thời gian quá ngắn\n",
    "min_series_length = max_encoder_length + max_prediction_length\n",
    "series_lengths = df.groupby('parent_asin')['time_idx'].count()\n",
    "valid_series_ids = series_lengths[series_lengths >= min_series_length].index\n",
    "df_filtered = df[df['parent_asin'].isin(valid_series_ids)].copy()\n",
    "\n",
    "if df_filtered.empty:\n",
    "    print(f\"Không có chuỗi thời gian nào đủ dài cho max_encoder_length={max_encoder_length} \"\n",
    "          f\"và max_prediction_length={max_prediction_length}. Hãy thử giảm các giá trị này.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(f\"Số dòng sau khi lọc các chuỗi ngắn: {df_filtered.shape[0]}\")\n",
    "\n",
    "\n",
    "# Xác định điểm cắt cho tập huấn luyện và kiểm định\n",
    "# Ví dụ: sử dụng 80% dữ liệu (theo time_idx tổng thể hoặc theo từng nhóm) cho huấn luyện\n",
    "# Cách tiếp cận tốt là chia theo một mốc thời gian cụ thể.\n",
    "# Ở đây, chúng ta sẽ chia theo `time_idx` cuối cùng.\n",
    "training_cutoff = df_filtered[\"time_idx\"].max() - max_prediction_length * 5 # Giữ lại 5*prediction_length cho validation\n",
    "\n",
    "# Xử lý NaN trong target một cách cẩn thận trước khi tạo dataset\n",
    "# print(f\"Số NaN trong cột rating trước khi tạo dataset: {df_filtered['rating'].isnull().sum()}\")\n",
    "# df_filtered.dropna(subset=['rating'], inplace=True) # Rất quan trọng\n",
    "\n",
    "# Các cột đặc trưng\n",
    "static_categoricals = ['store', 'main_category', 'main_cat_from_list'] # parent_asin là group_id\n",
    "# static_reals = [] # Nếu có\n",
    "\n",
    "time_varying_known_categoricals = ['month', 'year', 'day_of_week', 'day_of_month', 'week_of_year']\n",
    "time_varying_known_reals = ['day_of_year'] # `price` có thể là known nếu được đặt trước\n",
    "\n",
    "time_varying_unknown_reals = ['price', 'average_rating', 'rating_number', 'sentiment_score']\n",
    "# Nếu bạn có text embeddings (dạng vector số thực), chúng sẽ vào đây.\n",
    "# time_varying_unknown_categoricals = [] # Nếu có\n",
    "\n",
    "# Đảm bảo các cột này tồn tại trong df_filtered và có kiểu dữ liệu phù hợp\n",
    "cols_to_check = static_categoricals + \\\n",
    "                time_varying_known_categoricals + time_varying_known_reals + \\\n",
    "                time_varying_unknown_reals + ['parent_asin', 'rating', 'time_idx']\n",
    "\n",
    "for col in cols_to_check:\n",
    "    if col not in df_filtered.columns:\n",
    "        print(f\"CẢNH BÁO: Cột '{col}' không tồn tại trong DataFrame!\")\n",
    "        # Xử lý bằng cách loại bỏ khỏi danh sách hoặc tạo cột giả\n",
    "        if col in static_categoricals: static_categoricals.remove(col)\n",
    "        # ... tương tự cho các danh sách khác\n",
    "\n",
    "# Loại bỏ các cột không có trong df_filtered khỏi danh sách đặc trưng\n",
    "static_categoricals = [col for col in static_categoricals if col in df_filtered.columns]\n",
    "time_varying_known_categoricals = [col for col in time_varying_known_categoricals if col in df_filtered.columns]\n",
    "time_varying_known_reals = [col for col in time_varying_known_reals if col in df_filtered.columns]\n",
    "time_varying_unknown_reals = [col for col in time_varying_unknown_reals if col in df_filtered.columns]\n",
    "\n",
    "\n",
    "try:\n",
    "    training_dataset = TimeSeriesDataSet(\n",
    "        df_filtered[lambda x: x.time_idx <= training_cutoff],\n",
    "        time_idx=\"time_idx\",\n",
    "        target=\"rating\",\n",
    "        group_ids=[\"parent_asin\"],\n",
    "        max_encoder_length=max_encoder_length,\n",
    "        max_prediction_length=max_prediction_length,\n",
    "        min_prediction_length=max_prediction_length,\n",
    "        static_categoricals=static_categoricals,\n",
    "        # static_reals=static_reals,\n",
    "        time_varying_known_categoricals=time_varying_known_categoricals,\n",
    "        time_varying_known_reals=time_varying_known_reals,\n",
    "        time_varying_unknown_reals=time_varying_unknown_reals,\n",
    "        # time_varying_unknown_categoricals=time_varying_unknown_categoricals,\n",
    "        target_normalizer=GroupNormalizer(groups=[\"parent_asin\"]),\n",
    "\n",
    "        add_relative_time_idx=True,\n",
    "        add_target_scales=True,\n",
    "        add_encoder_length=True,\n",
    "        allow_missing_timesteps=True,\n",
    "        categorical_encoders={col: NaNLabelEncoder(add_nan=True) for col in static_categoricals + time_varying_known_categoricals if col in df_filtered.columns}\n",
    "    )\n",
    "\n",
    "    # Tạo tập kiểm định (validation set)\n",
    "    # Đảm bảo dữ liệu kiểm định bắt đầu sau dữ liệu huấn luyện\n",
    "    validation_dataset = TimeSeriesDataSet.from_dataset(\n",
    "        training_dataset, # Kế thừa các encoders, scaling từ tập training\n",
    "        df_filtered[lambda x: x.time_idx > training_cutoff],\n",
    "        min_prediction_idx=training_cutoff + 1, # Bắt đầu dự đoán sau điểm cắt\n",
    "        stop_randomization=True # Quan trọng cho tập kiểm định\n",
    "    )\n",
    "\n",
    "    # Tạo Dataloaders\n",
    "    batch_size = 128  # Điều chỉnh dựa trên bộ nhớ của bạn\n",
    "    # num_workers=0 nếu chạy trên Windows hoặc Jupyter notebook để tránh lỗi\n",
    "    train_dataloader = training_dataset.to_dataloader(train=True, batch_size=batch_size, num_workers=4)\n",
    "    val_dataloader = validation_dataset.to_dataloader(train=False, batch_size=batch_size * 2, num_workers=4)\n",
    "    \n",
    "    train_dataloader.pin_memory = True\n",
    "    val_dataloader.pin_memory = True\n",
    "    print(\"TimeSeriesDataSet và DataLoaders đã được tạo thành công.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi tạo TimeSeriesDataSet hoặc Dataloaders: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    print(\"Kiểm tra các vấn đề sau:\")\n",
    "    print(\"- NaN trong các cột quan trọng (target, group_ids, time_idx).\")\n",
    "    print(\"- Các đặc trưng hạng mục có được mã hóa đúng cách hoặc là kiểu chuỗi không.\")\n",
    "    print(\"- Tất cả các cột đặc trưng được chỉ định có tồn tại trong DataFrame và có kiểu nhất quán không.\")\n",
    "    print(\"- Độ dài chuỗi thời gian có đủ không.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "926008dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng tham số trong mạng: 80.0k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42) # Để có thể tái tạo kết quả\n",
    "\n",
    "# Định nghĩa mô hình TFT\n",
    "# Điều chỉnh các siêu tham số như hidden_size, lstm_layers, num_heads, dropout\n",
    "# dựa trên kích thước và độ phức tạp của bộ dữ liệu.\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training_dataset,\n",
    "    learning_rate=0.001, # Tốc độ học phổ biến: 0.001 đến 0.1\n",
    "    hidden_size=32,        # Kích thước lớp ẩn (ví dụ: 16, 32, 64)\n",
    "    attention_head_size=4, # Số lượng attention heads\n",
    "    dropout=0.1,           # Tỷ lệ dropout\n",
    "    hidden_continuous_size=16, # Kích thước lớp ẩn cho biến liên tục\n",
    "    output_size=7,         # Số lượng quantiles để dự đoán (7 cho QuantileLoss mặc định)\n",
    "                           # Nếu bạn muốn dự đoán một giá trị cụ thể, có thể đặt loss là MAE() hoặc SMAPE()\n",
    "                           # và output_size=1, nhưng TFT thường được thiết lập cho quantiles.\n",
    "    loss=QuantileLoss(),   # Hàm mất mát (QuantileLoss, MAE, SMAPE)\n",
    "    # reduce_on_plateau_patience=4 # Cho learning rate scheduler\n",
    ")\n",
    "print(f\"Số lượng tham số trong mạng: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d898525d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu126\n",
      "PyTorch Lightning version: 2.5.1.post0\n",
      "Pytorch Forecasting version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Lightning version: {pl.__version__}\")\n",
    "print(f\"Pytorch Forecasting version: {pytorch_forecasting.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4074f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of tft object: <class 'pytorch_forecasting.models.temporal_fusion_transformer._tft.TemporalFusionTransformer'>\n",
      "Is tft a LightningModule? False\n",
      "Is tft a TemporalFusionTransformer from pytorch_forecasting? True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Type of tft object: {type(tft)}\")\n",
    "print(f\"Is tft a LightningModule? {isinstance(tft, pl.LightningModule)}\")\n",
    "print(f\"Is tft a TemporalFusionTransformer from pytorch_forecasting? {isinstance(tft, TemporalFusionTransformer)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1635d414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kiểm tra batch từ train_dataloader (dạng tuple):\n",
      "  Batch không phải là tuple.\n",
      "\n",
      "Kiểm tra batch từ val_dataloader (dạng tuple):\n",
      "  Batch không phải là tuple.\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(\"Kiểm tra batch từ train_dataloader (dạng tuple):\")\n",
    "    if isinstance(batch, tuple):\n",
    "        for i, tensor in enumerate(batch):\n",
    "            if isinstance(tensor, torch.Tensor):\n",
    "                print(f\"  Tensor tại index {i} có device: {tensor.device}\")\n",
    "            else:\n",
    "                print(f\"  Phần tử tại index {i} không phải là tensor (type: {type(tensor)})\")\n",
    "    else:\n",
    "        print(\"  Batch không phải là tuple.\")\n",
    "    break\n",
    "\n",
    "for batch in val_dataloader:\n",
    "    print(\"\\nKiểm tra batch từ val_dataloader (dạng tuple):\")\n",
    "    if isinstance(batch, tuple):\n",
    "        for i, tensor in enumerate(batch):\n",
    "            if isinstance(tensor, torch.Tensor):\n",
    "                print(f\"  Tensor tại index {i} có device: {tensor.device}\")\n",
    "            else:\n",
    "                print(f\"  Phần tử tại index {i} không phải là tensor (type: {type(tensor)})\")\n",
    "    else:\n",
    "        print(\"  Batch không phải là tuple.\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d753249a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kiểm tra tensors trong batch từ train_dataloader:\n",
      "  Cấu trúc batch không như mong đợi cho train_dataloader.\n",
      "\n",
      "Kiểm tra tensors trong batch từ val_dataloader:\n",
      "  Cấu trúc batch không như mong đợi cho val_dataloader.\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(\"Kiểm tra tensors trong batch từ train_dataloader:\")\n",
    "    if isinstance(batch, tuple) and isinstance(batch[0], dict):\n",
    "        input_dict = batch[0]\n",
    "        for key, value in input_dict.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                print(f\"  Tensor '{key}' có device: {value.device}\")\n",
    "            else:\n",
    "                print(f\"  '{key}' không phải là tensor (type: {type(value)})\")\n",
    "    else:\n",
    "        print(\"  Cấu trúc batch không như mong đợi cho train_dataloader.\")\n",
    "    break\n",
    "\n",
    "for batch in val_dataloader:\n",
    "    print(\"\\nKiểm tra tensors trong batch từ val_dataloader:\")\n",
    "    if isinstance(batch, tuple) and isinstance(batch[0], dict):\n",
    "        input_dict = batch[0]\n",
    "        for key, value in input_dict.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                print(f\"  Tensor '{key}' có device: {value.device}\")\n",
    "            else:\n",
    "                print(f\"  '{key}' không phải là tensor (type: {type(value)})\")\n",
    "    else:\n",
    "        print(\"  Cấu trúc batch không như mong đợi cho val_dataloader.\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51841228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                      | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | tft_model | TemporalFusionTransformer | 80.0 K | train\n",
      "----------------------------------------------------------------\n",
      "80.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "80.0 K    Total params\n",
      "0.320     Total estimated model params size (MB)\n",
      "385       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu huấn luyện mô hình...\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Đã xảy ra lỗi trong quá trình huấn luyện: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_22144\\1721587369.py\", line 66, in <module>\n",
      "    trainer.fit(\n",
      "  File \"c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 561, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py\", line 48, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 599, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 1012, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 1054, in _run_stage\n",
      "    self._run_sanity_check()\n",
      "  File \"c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 1083, in _run_sanity_check\n",
      "    val_loop.run()\n",
      "  File \"c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py\", line 179, in _decorator\n",
      "    return loop_run(self, *args, **kwargs)\n",
      "  File \"c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py\", line 145, in run\n",
      "    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n",
      "  File \"c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py\", line 437, in _evaluation_step\n",
      "    output = call._call_strategy_hook(trainer, hook_name, *step_args)\n",
      "  File \"c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py\", line 328, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py\", line 412, in validation_step\n",
      "    return self.lightning_module.validation_step(*args, **kwargs)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_22144\\1721587369.py\", line 25, in validation_step\n",
      "    y_hat = self.tft_model(x)\n",
      "  File \"c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\pytorch_forecasting\\models\\temporal_fusion_transformer\\_tft.py\", line 625, in forward\n",
      "    mask=self.get_attention_mask(\n",
      "  File \"c:\\Users\\PC\\anaconda3\\envs\\DL_env\\lib\\site-packages\\pytorch_forecasting\\models\\temporal_fusion_transformer\\_tft.py\", line 498, in get_attention_mask\n",
      "    mask = torch.cat(\n",
      "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_forecasting import TemporalFusionTransformer\n",
    "\n",
    "# Giả sử bạn đã có train_dataloader và val_dataloader\n",
    "\n",
    "\n",
    "# Định nghĩa một LightningModule bao bọc mô hình TFT\n",
    "class TFTLightningModule(pl.LightningModule):\n",
    "    def __init__(self, tft_model, learning_rate):\n",
    "        super().__init__()\n",
    "        self.tft_model = tft_model\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.tft_model(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.tft_model(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def loss_fn(self, y_hat, y):\n",
    "        # Định nghĩa hàm loss phù hợp với đầu ra của mô hình và nhãn\n",
    "        # Ví dụ: Mean Squared Error (MSE)\n",
    "        return torch.mean((y_hat - y)**2)\n",
    "\n",
    "# Cấu hình Trainer của PyTorch Lightning\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor() # Theo dõi tốc độ học\n",
    "\n",
    "# Kiểm tra xem GPU có sẵn không\n",
    "accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "devices = 1 if torch.cuda.is_available() else None\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5, # Bắt đầu với số lượng epochs nhỏ để kiểm tra pipeline (ví dụ: 3-10)\n",
    "                  # Tăng lên sau (ví dụ: 50-100)\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    "    gradient_clip_val=0.1, # Giúp ổn định quá trình huấn luyện\n",
    "    limit_train_batches=50,  # Giới hạn số batch cho mỗi epoch để lặp nhanh hơn trong quá trình phát triển\n",
    "    limit_val_batches=20,\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    # logger=pl.loggers.TensorBoardLogger(\"lightning_logs\") # Để sử dụng TensorBoard\n",
    ")\n",
    "\n",
    "# Khởi tạo LightningModule với mô hình tft và learning rate\n",
    "learning_rate = 0.001 # Điều chỉnh learning rate nếu cần\n",
    "tft_lightning = TFTLightningModule(tft, learning_rate)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "try:\n",
    "    print(\"Bắt đầu huấn luyện mô hình...\")\n",
    "    trainer.fit(\n",
    "        tft_lightning,\n",
    "        train_dataloaders=train_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    "    )\n",
    "    print(\"Hoàn thành huấn luyện mô hình.\")\n",
    "except Exception as e:\n",
    "    print(f\"Đã xảy ra lỗi trong quá trình huấn luyện: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce71251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde2e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af054b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac854f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Không tìm thấy checkpoint mô hình tốt nhất. Có thể quá trình huấn luyện chưa tạo checkpoint.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Tải mô hình tốt nhất từ checkpoint\n",
    "    best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "    if best_model_path:\n",
    "        print(f\"Đang tải mô hình tốt nhất từ: {best_model_path}\")\n",
    "        best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
    "\n",
    "        # Đánh giá trên tập kiểm định\n",
    "        actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "        raw_predictions = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)\n",
    "        predictions = raw_predictions.output # Lấy phần output của dự đoán\n",
    "\n",
    "        # Nếu sử dụng QuantileLoss, predictions sẽ có dạng [batch_size, prediction_length, num_quantiles]\n",
    "        # Để có một dự đoán điểm, bạn có thể lấy quantile giữa (thường là median).\n",
    "        if tft.loss.quantiles:\n",
    "            median_prediction_index = len(tft.loss.quantiles) // 2\n",
    "            point_predictions = predictions[:, :, median_prediction_index]\n",
    "        else: # Nếu loss là MAE hoặc SMAPE, predictions đã là dự đoán điểm\n",
    "            point_predictions = predictions.squeeze(-1) # Bỏ chiều cuối nếu nó là 1\n",
    "\n",
    "        # Tính toán MAE (Mean Absolute Error)\n",
    "        mae_value = (actuals - point_predictions).abs().mean()\n",
    "        print(f\"Validation MAE (trên dự đoán điểm): {mae_value.item()}\")\n",
    "\n",
    "        # Bạn cũng có thể tính các độ đo khác như RMSE, SMAPE tùy thuộc vào hàm loss đã chọn.\n",
    "\n",
    "        # Xem một vài dự đoán mẫu\n",
    "        print(\"\\nDự đoán mẫu (5 dự đoán đầu tiên):\")\n",
    "        for i in range(min(5, len(actuals))):\n",
    "            print(f\"Thực tế: {actuals[i].item():.2f}, Dự đoán: {point_predictions[i].item():.2f}\")\n",
    "\n",
    "        # Trực quan hóa dự đoán (tùy chọn, cần matplotlib)\n",
    "        # import matplotlib.pyplot as plt\n",
    "        # sample_idx = 0 # Chọn một mẫu để vẽ\n",
    "        # true_values = raw_predictions.x['decoder_target'][sample_idx] # Giá trị thực tế trong khoảng dự đoán\n",
    "        # predicted_values = point_predictions[sample_idx]\n",
    "        # past_values = raw_predictions.x['encoder_target'][sample_idx] # Giá trị trong encoder (quá khứ)\n",
    "\n",
    "        # plt.figure(figsize=(12, 6))\n",
    "        # time_steps_past = np.arange(-len(past_values), 0)\n",
    "        # time_steps_future = np.arange(0, len(true_values))\n",
    "\n",
    "        # plt.plot(time_steps_past, past_values, label=\"Lịch sử Rating (Encoder)\")\n",
    "        # plt.plot(time_steps_future, true_values, label=\"Rating Thực tế (Decoder)\")\n",
    "        # plt.plot(time_steps_future, predicted_values, label=\"Rating Dự đoán\")\n",
    "        # plt.title(f\"Dự đoán Rating cho một sản phẩm (mẫu {sample_idx})\")\n",
    "        # plt.xlabel(\"Bước thời gian (tương đối)\")\n",
    "        # plt.ylabel(\"Rating\")\n",
    "        # plt.legend()\n",
    "        # plt.show()\n",
    "\n",
    "    else:\n",
    "        print(\"Không tìm thấy checkpoint mô hình tốt nhất. Có thể quá trình huấn luyện chưa tạo checkpoint.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Đã xảy ra lỗi trong quá trình đánh giá hoặc dự đoán: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
